{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "import geopandas as gpd\n",
    "from shapely.wkt import loads\n",
    "from pyproj import Proj, Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lat_lon_to_axis(lat, lon, axis_direction=(1, 0), crs=\"EPSG:3857\"):\n",
    "    \"\"\"\n",
    "    Convert latitude and longitude to a one-dimensional value in meters along an axis.\n",
    "\n",
    "    Args:\n",
    "        lat (float): Latitude of the point.\n",
    "        lon (float): Longitude of the point.\n",
    "        axis_direction (tuple): Direction vector of the axis (x, y).\n",
    "        crs (str): CRS for projecting to meters (default: EPSG:3857).\n",
    "\n",
    "    Returns:\n",
    "        float: One-dimensional projection value in meters.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the transformer for projecting lat/lon to the desired CRS\n",
    "    transformer = Transformer.from_crs(\"EPSG:4326\", crs, always_xy=True)\n",
    "    \n",
    "    # Project the latitude and longitude to meters\n",
    "    x, y = transformer.transform(lon, lat)\n",
    "    \n",
    "    # Normalize the axis direction vector\n",
    "    axis_vector = np.array(axis_direction)\n",
    "    axis_unit_vector = axis_vector / np.linalg.norm(axis_vector)\n",
    "    \n",
    "    # Compute the projection of the point onto the axis\n",
    "    projection_value = np.dot([x, y], axis_unit_vector)\n",
    "    return projection_value\n",
    "\n",
    "def find_traffic_light_id(row, segments_gdf):\n",
    "    \"\"\"\n",
    "    Find the nearest segment ID to a given row in a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        row (pd.Series): Row in a DataFrame with columns 'lat' and 'lon'.\n",
    "        segments_gdf (gpd.GeoDataFrame): GeoDataFrame with segment geometries.\n",
    "\n",
    "    Returns:\n",
    "        int: ID of the nearest segment.\n",
    "    \"\"\"\n",
    "    # Create a GeoDataFrame for the point\n",
    "    point = gpd.GeoDataFrame(\n",
    "        geometry=[loads(f\"POINT ({row['lat']} {row['lon']})\")], crs=\"EPSG:4326\" # Make sure lat and lon is given completely right! Lat first then lon\n",
    "    )\n",
    "    \n",
    "    # Reproject both point and segments to a projected CRS for accurate distance calculations\n",
    "    projected_crs = \"EPSG:4326\"  # Common projected CRS for distance calculations\n",
    "    point_proj = point.to_crs(projected_crs)\n",
    "    segments_gdf_proj = segments_gdf.to_crs(projected_crs)\n",
    "    max_distance = float(\"inf\")\n",
    "    nearest_link_id = None\n",
    "    for index, row in segments_gdf_proj.iterrows():\n",
    "        distance = row.geometry.distance(point_proj.geometry[0])\n",
    "        if distance < max_distance:\n",
    "            max_distance = distance\n",
    "            nearest_link_id = index\n",
    "    return nearest_link_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the main dataframe\n",
    "main_df = pd.read_csv(\"20181024_d1_0830_0900_traffic_segmented.csv\")\n",
    "# loading the traffic light states\n",
    "with open(\"20181024_d1_0830_0900_traffic_light_states.json\") as f:\n",
    "    traffic_info = json.load(f)\n",
    "# loading the segments\n",
    "segments_gdf = gpd.read_file(\"20181024_d1_0830_0900_traffic_lights_segments.csv\")\n",
    "# Convert to GeoDataFrame\n",
    "if \"geometry\" in segments_gdf.columns:\n",
    "    # Convert 'geometry' to shapely objects if needed\n",
    "    segments_gdf[\"geometry\"] = segments_gdf[\"geometry\"].apply(loads)\n",
    "    # Create GeoDataFrame and set the CRS to WGS 84 (latitude/longitude)\n",
    "    segments_gdf = gpd.GeoDataFrame(segments_gdf, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "else:\n",
    "    raise ValueError(\"The DataFrame does not have a 'geometry' column.\")\n",
    "\n",
    "# Reproject to a projected CRS (replace EPSG code with appropriate UTM zone)\n",
    "segments_gdf = segments_gdf.to_crs(\"EPSG:25832\")  # Example for UTM Zone 32N\n",
    "\n",
    "# Calculate lengths\n",
    "segments_gdf[\"length\"] = segments_gdf.geometry.length\n",
    "segments_gdf = segments_gdf.to_crs(\"EPSG:4326\")  # Example for UTM Zone 32N\n",
    "\n",
    "lon_one_axis_trajectory = []\n",
    "lat_one_axis_trajectory = []\n",
    "for i, row in segments_gdf.iterrows():\n",
    "    lat_one_axis_trajectory.append(lat_lon_to_axis(row.geometry.coords.xy[0][1], row.geometry.coords.xy[0][0], crs=\"EPSG:4326\"))\n",
    "    lon_one_axis_trajectory.append(lat_lon_to_axis(row.geometry.coords.xy[1][1], row.geometry.coords.xy[1][0], crs=\"EPSG:4326\"))\n",
    "\n",
    "segments_gdf[\"lon_one_axis_trajectory\"] = lon_one_axis_trajectory\n",
    "segments_gdf[\"lat_one_axis_trajectory\"] = lat_one_axis_trajectory\n",
    "\n",
    "# Calculate total length\n",
    "total_length = segments_gdf[\"length\"].sum()\n",
    "\n",
    "# loading the traffic lights\n",
    "traffic_lights_df = pd.read_csv(\"traffic_lights.csv\")\n",
    "# find traffic light segment id\n",
    "traffic_lights_df[\"nearest_link_id\"] = traffic_lights_df.apply(find_traffic_light_id, axis=1, segments_gdf=segments_gdf)\n",
    "traffic_lights_df = traffic_lights_df.iloc[:5, :]\n",
    "# loading the traffic light states\n",
    "with open(\"traffic_info_dict.pkl\", \"rb\") as f:\n",
    "    traffic_lights_dict_states = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "main_df_truncated_with_cell = pd.read_csv(\"20181024_d1_0830_0900_segmented_oneaxistrajectory_cell_main.csv\")\n",
    "\n",
    "# Group by the desired columns and aggregate the vehicle IDs into a frozenset\n",
    "grouped_with_veh_ids = main_df_truncated_with_cell.groupby([\"link_id\", \"time\"]).agg({\n",
    "    \"veh_id\": lambda x: frozenset(x)  # Use frozenset instead of set\n",
    "}).reset_index()\n",
    "\n",
    "# Merge the new column back into the original dataframe\n",
    "main_df_truncated_with_cell = main_df_truncated_with_cell.merge(grouped_with_veh_ids, on=[\"link_id\", \"time\"], suffixes=('', '_list'))\n",
    "\n",
    "# Rename the new column for clarity\n",
    "main_df_truncated_with_cell.rename(columns={\"veh_id_list\": \"veh_id_list\"}, inplace=True)\n",
    "\n",
    "# Display the shapes\n",
    "duplicate_dropped = main_df_truncated_with_cell.drop_duplicates(subset=[\"link_id\", \"time\", \"veh_id_list\"])[[\"veh_id_list\", \"link_id\", \"time\"]]\n",
    "\n",
    "\n",
    "link_dataframes = {}\n",
    "for link_id in duplicate_dropped[\"link_id\"].unique():\n",
    "    \n",
    "    segment_df = duplicate_dropped[duplicate_dropped[\"link_id\"] == link_id].reset_index().drop(columns=[\"index\"])\n",
    "    segment_df = segment_df.sort_values(\"time\")\n",
    "\n",
    "    segment_df[\"N_down\"] = segment_df[\"veh_id_list\"] - segment_df[\"veh_id_list\"].shift(1)\n",
    "    segment_df[\"N_up\"] = segment_df[\"veh_id_list\"].shift(-1) - segment_df[\"veh_id_list\"] \n",
    "\n",
    "    segment_df[\"N_cumsum_down\"] = segment_df[\"N_down\"].iloc[1:].apply(len).cumsum()\n",
    "    segment_df[\"N_cumsum_up\"] = segment_df[\"N_up\"].iloc[:-1].apply(len).cumsum()\n",
    "    \n",
    "    link_dataframes[link_id] = segment_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def cumulativecount_up(time, link_id):\n",
    "    segment_df = link_dataframes[link_id]\n",
    "    closest_time = segment_df[segment_df['time'] <= time].time.max()\n",
    "    if math.isnan(closest_time):\n",
    "        return 0\n",
    "    return segment_df[segment_df['time'] == closest_time][\"N_cumsum_up\"].values[0]\n",
    "\n",
    "def cumulativecount_down(time, link_id):\n",
    "    segment_df = link_dataframes[link_id]\n",
    "    closest_time = segment_df[segment_df['time'] <= time].time.max()\n",
    "    if math.isnan(closest_time):\n",
    "        return 0\n",
    "    return segment_df[segment_df['time'] == closest_time][\"N_cumsum_down\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import CTMParameters\n",
    "from helper import *\n",
    "import math\n",
    "\n",
    "# Notes for Maziar:\n",
    "## Do not use CTMParameters().object at all! If you use it, it will create a new object every time you call it. Instead, use the instance that you make of it!\n",
    "## Try avoidng using the istance of CTMParemeters as a global object. Instead, pass it as an argument to the functions that need it.\n",
    "## The docstring could be formatted for clarity: 1- Mention all parameters and their expected types! 2- Include an explanation of the function's output!\n",
    "## Check for invalid or empty densities.\n",
    "## Use descriptive variable names for better readability.\n",
    "## Avoid magic numbers like 1 for the green light status; use constants instead.\n",
    "\n",
    "\n",
    "# load params\n",
    "ctm_params = CTMParameters() # for now, we use same parameters we had in CTM model\n",
    "\n",
    "# define the function for finding cumulative counts\n",
    "N_upstr = cumulativecount_up\n",
    "N_downstr = cumulativecount_down\n",
    "\n",
    "## spatial queue model: update number of vehicles in the link\n",
    "# time: current simulation time\n",
    "# arguments: N_upstrs: cumulative count of vehicles in upstream at a given time. I'll pass N_downstr(t) and it should tell me the cumulative count\n",
    "# N_downstr: cumulative count at link downstream at time t (current time)\n",
    "# entry_flow: for now constant, average number of vehicles entering to the link in vehicles per second\n",
    "# assumptions: queue forms at the link downstream\n",
    "def update_spatial_queue(time, link_id, entry_flow, traffic_lights_df, traffic_lights_dict_states):\n",
    "\n",
    "    #find the receiving flow, including the entry flow\n",
    "    receceiving_flow = min( entry_flow*ctm_params.time_step, ctm_params.segment_length*ctm_params.jam_density - (N_upstr(time,link_id) - N_downstr(time,link_id)), ctm_params.max_flow()*ctm_params.time_step)\n",
    "    \n",
    "    # check if there is a traffic light at the end of the segment\n",
    "    if is_tl(link_id, traffic_lights_df):\n",
    "        # check the status of the traffic light\n",
    "        if tl_status(time, link_id, traffic_lights_df, traffic_lights_dict_states) == 1: # green light\n",
    "            # find the link sending flow using point queue model \n",
    "            sending_flow = min( N_upstr(time + ctm_params.time_step - (ctm_params.segment_length/ctm_params.free_flow_speed), link_id) - N_downstr(time, link_id), ctm_params.max_flow()*ctm_params.time_step)      \n",
    "        else:\n",
    "            sending_flow = 0\n",
    "    else: # no traffic light at the end of the link\n",
    "        sending_flow = min( N_upstr(time + ctm_params.time_step - (ctm_params.segment_length/ctm_params.free_flow_speed), link_id) - N_downstr(time, link_id), ctm_params.max_flow()*ctm_params.time_step)\n",
    "\n",
    "    # find the number of vehicles in the link at the next time step\n",
    "    n_current = N_downstr(time, link_id) - N_upstr(time, link_id)   # current number of vehicles\n",
    "    n_updated = n_current + receceiving_flow - sending_flow \n",
    "\n",
    "    link_outflow = sending_flow\n",
    "    link_density = n_updated / ctm_params.segment_length\n",
    "    return link_density, link_outflow    # please note the order \n",
    "\n",
    "# # test the function\n",
    "# Density = [0.1, 0.15, 0, 0.2, 0.1, 0.1]\n",
    "# entry_flow = 0.1\n",
    "# time = 5\n",
    "# updated_density = update_point_queue(time, 1, Density, ctm_params, entry_flow)\n",
    "# print(updated_density)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get inflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inflow = pd.read_csv(\"20181024_d1_0830_0900_inflow.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "point_queue_data = defaultdict(dict)\n",
    "\n",
    "for link_id in duplicate_dropped[\"link_id\"].unique():\n",
    "    segment_df = duplicate_dropped[duplicate_dropped[\"link_id\"] == link_id].reset_index().drop(columns=[\"index\"])\n",
    "    segment_df = segment_df.sort_values(\"time\")\n",
    "    for time in segment_df[\"time\"].unique():\n",
    "            \n",
    "        entry_flow = inflow[(inflow[\"link_id\"] == link_id) & (inflow[\"time\"] == time)][\"inflow\"]\n",
    "        if entry_flow.empty:\n",
    "            entry_flow = 0\n",
    "        else:\n",
    "            entry_flow = entry_flow.values[0]\n",
    "        \n",
    "        link_density, link_outflow = update_spatial_queue(time, link_id, entry_flow, traffic_lights_df, traffic_lights_dict_states)\n",
    "        \n",
    "        point_queue_data[link_id][time] = {\"link_density\": link_density, \"link_outflow\": link_outflow}\n",
    "        # print(time, link_id, \"done\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"20181024_d1_0830_0900_result_spatial_queue.pkl\", \"wb\") as f:\n",
    "    pickle.dump(point_queue_data, f)\n",
    "\n",
    "\n",
    "point_queue_data = pickle.load(open(\"20181024_d1_0830_0900_result_spatial_queue.pkl\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>veh_id_list</th>\n",
       "      <th>link_id</th>\n",
       "      <th>time</th>\n",
       "      <th>no_veh</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1, 59, 60, 84)</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1, 59, 60, 84)</td>\n",
       "      <td>4</td>\n",
       "      <td>0.04</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1, 59, 60, 84)</td>\n",
       "      <td>4</td>\n",
       "      <td>0.08</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(1, 59, 60, 84)</td>\n",
       "      <td>4</td>\n",
       "      <td>0.12</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1, 59, 60, 84)</td>\n",
       "      <td>4</td>\n",
       "      <td>0.16</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694918</th>\n",
       "      <td>(899, 903, 904, 906, 908, 909, 911, 913, 914, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>818.64</td>\n",
       "      <td>12</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694919</th>\n",
       "      <td>(899, 903, 904, 906, 908, 909, 911, 913, 914, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>818.68</td>\n",
       "      <td>12</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694920</th>\n",
       "      <td>(899, 903, 904, 906, 908, 909, 911, 913, 914, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>818.72</td>\n",
       "      <td>12</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694921</th>\n",
       "      <td>(899, 903, 904, 906, 908, 909, 911, 913, 914, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>818.76</td>\n",
       "      <td>12</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694922</th>\n",
       "      <td>(899, 903, 904, 906, 908, 909, 911, 913, 914, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>818.80</td>\n",
       "      <td>12</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99176 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              veh_id_list  link_id    time  \\\n",
       "0                                         (1, 59, 60, 84)        4    0.00   \n",
       "1                                         (1, 59, 60, 84)        4    0.04   \n",
       "2                                         (1, 59, 60, 84)        4    0.08   \n",
       "3                                         (1, 59, 60, 84)        4    0.12   \n",
       "4                                         (1, 59, 60, 84)        4    0.16   \n",
       "...                                                   ...      ...     ...   \n",
       "694918  (899, 903, 904, 906, 908, 909, 911, 913, 914, ...        0  818.64   \n",
       "694919  (899, 903, 904, 906, 908, 909, 911, 913, 914, ...        0  818.68   \n",
       "694920  (899, 903, 904, 906, 908, 909, 911, 913, 914, ...        0  818.72   \n",
       "694921  (899, 903, 904, 906, 908, 909, 911, 913, 914, ...        0  818.76   \n",
       "694922  (899, 903, 904, 906, 908, 909, 911, 913, 914, ...        0  818.80   \n",
       "\n",
       "        no_veh  density  \n",
       "0            4      0.1  \n",
       "1            4      0.1  \n",
       "2            4      0.1  \n",
       "3            4      0.1  \n",
       "4            4      0.1  \n",
       "...        ...      ...  \n",
       "694918      12      0.3  \n",
       "694919      12      0.3  \n",
       "694920      12      0.3  \n",
       "694921      12      0.3  \n",
       "694922      12      0.3  \n",
       "\n",
       "[99176 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_dropped[\"no_veh\"] = duplicate_dropped[\"veh_id_list\"].apply(len)\n",
    "duplicate_dropped[\"density\"] = duplicate_dropped[\"no_veh\"] / ctm_params.segment_length\n",
    "duplicate_dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the spatial queue model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>veh_id_list</th>\n",
       "      <th>link_id</th>\n",
       "      <th>time</th>\n",
       "      <th>no_veh</th>\n",
       "      <th>density</th>\n",
       "      <th>predicted_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1, 59, 60, 84)</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1, 59, 60, 84)</td>\n",
       "      <td>4</td>\n",
       "      <td>0.04</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1, 59, 60, 84)</td>\n",
       "      <td>4</td>\n",
       "      <td>0.08</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(1, 59, 60, 84)</td>\n",
       "      <td>4</td>\n",
       "      <td>0.12</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1, 59, 60, 84)</td>\n",
       "      <td>4</td>\n",
       "      <td>0.16</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694918</th>\n",
       "      <td>(899, 903, 904, 906, 908, 909, 911, 913, 914, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>818.64</td>\n",
       "      <td>12</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694919</th>\n",
       "      <td>(899, 903, 904, 906, 908, 909, 911, 913, 914, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>818.68</td>\n",
       "      <td>12</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694920</th>\n",
       "      <td>(899, 903, 904, 906, 908, 909, 911, 913, 914, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>818.72</td>\n",
       "      <td>12</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694921</th>\n",
       "      <td>(899, 903, 904, 906, 908, 909, 911, 913, 914, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>818.76</td>\n",
       "      <td>12</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694922</th>\n",
       "      <td>(899, 903, 904, 906, 908, 909, 911, 913, 914, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>818.80</td>\n",
       "      <td>12</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99176 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              veh_id_list  link_id    time  \\\n",
       "0                                         (1, 59, 60, 84)        4    0.00   \n",
       "1                                         (1, 59, 60, 84)        4    0.04   \n",
       "2                                         (1, 59, 60, 84)        4    0.08   \n",
       "3                                         (1, 59, 60, 84)        4    0.12   \n",
       "4                                         (1, 59, 60, 84)        4    0.16   \n",
       "...                                                   ...      ...     ...   \n",
       "694918  (899, 903, 904, 906, 908, 909, 911, 913, 914, ...        0  818.64   \n",
       "694919  (899, 903, 904, 906, 908, 909, 911, 913, 914, ...        0  818.68   \n",
       "694920  (899, 903, 904, 906, 908, 909, 911, 913, 914, ...        0  818.72   \n",
       "694921  (899, 903, 904, 906, 908, 909, 911, 913, 914, ...        0  818.76   \n",
       "694922  (899, 903, 904, 906, 908, 909, 911, 913, 914, ...        0  818.80   \n",
       "\n",
       "        no_veh  density  predicted_density  \n",
       "0            4      0.1                0.0  \n",
       "1            4      0.1                0.0  \n",
       "2            4      0.1                0.0  \n",
       "3            4      0.1                0.0  \n",
       "4            4      0.1                0.0  \n",
       "...        ...      ...                ...  \n",
       "694918      12      0.3                0.0  \n",
       "694919      12      0.3                0.0  \n",
       "694920      12      0.3                0.0  \n",
       "694921      12      0.3                0.0  \n",
       "694922      12      0.3                0.0  \n",
       "\n",
       "[99176 rows x 6 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_dropped[\"predicted_density\"] = duplicate_dropped.apply(lambda x: point_queue_data[x[\"link_id\"]][x[\"time\"]][\"link_density\"], axis=1).fillna(0)\n",
    "duplicate_dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSE for each link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For link with id:  0  the RMSE is:  0.1705591579149414\n",
      "For link with id:  1  the RMSE is:  0.12229215336909997\n",
      "For link with id:  2  the RMSE is:  0.27544378463041164\n",
      "For link with id:  3  the RMSE is:  0.19630552910448498\n",
      "For link with id:  4  the RMSE is:  0.07669708312597809\n"
     ]
    }
   ],
   "source": [
    "for link_id in sorted(duplicate_dropped[\"link_id\"].unique()):\n",
    "    rmse = np.sqrt(np.mean((duplicate_dropped[duplicate_dropped[\"link_id\"] == link_id][\"density\"] - duplicate_dropped[duplicate_dropped[\"link_id\"] == link_id][\"predicted_density\"])**2))\n",
    "    print(\"For link with id: \", link_id, \" the RMSE is: \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/08/xlt8ht5x04x0hg_fhxdwdl7m0000gr/T/ipykernel_72473/3001758016.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  duplicate_dropped.groupby(\"time\").apply(lambda x: x.set_index(\"link_id\")[\"e2\"].to_dict()).to_dict()\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "duplicate_dropped[\"e2\"] = (duplicate_dropped[\"density\"] - duplicate_dropped[\"predicted_density\"])**2\n",
    "duplicate_dropped.groupby(\"time\").apply(lambda x: x.set_index(\"link_id\")[\"e2\"].to_dict()).to_dict()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert the dictionary to a DataFrame for easier plotting\n",
    "heatmap_df = pd.DataFrame.from_dict(duplicate_dropped.groupby(\"time\").apply(lambda x: x.set_index(\"link_id\")[\"e2\"].to_dict()).to_dict(), orient='index')\n",
    "heatmap_df.index.name = 'time'\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(heatmap_df, cmap=\"Reds\", annot=False)\n",
    "plt.title(\"Heatmap of Squared Errors Over Time and Links\")\n",
    "plt.xlabel(\"Link ID\")\n",
    "plt.ylabel(\"Time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "threshold = heatmap_df.shape[0]\n",
    "data = heatmap_df.values[:threshold]\n",
    "\n",
    "# Fixed figure size\n",
    "fig_width = 1200\n",
    "fig_height = 800\n",
    "\n",
    "# Create the heatmap\n",
    "fig = px.imshow(\n",
    "    data,\n",
    "    labels=dict(x=\"Link ID\", y=\"Time\", color=\"Squared Error\"),\n",
    "    x=[str(i) for i in range(data.shape[1])],  \n",
    "    y=[heatmap_df.index[i] for i in range(threshold)],\n",
    "    color_continuous_scale=\"Viridis\"\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Fixed Size Interactive Heatmap\",\n",
    "    xaxis=dict(scaleanchor=\"x\", constrain=\"domain\"),\n",
    "    yaxis=dict(scaleanchor=\"y\", constrain=\"domain\"),\n",
    "    width=fig_width,\n",
    "    height=fig_height\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
