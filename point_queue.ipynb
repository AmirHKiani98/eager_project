{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "import geopandas as gpd\n",
    "from shapely.wkt import loads\n",
    "from pyproj import Proj, Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lat_lon_to_axis(lat, lon, axis_direction=(1, 0), crs=\"EPSG:3857\"):\n",
    "    \"\"\"\n",
    "    Convert latitude and longitude to a one-dimensional value in meters along an axis.\n",
    "\n",
    "    Args:\n",
    "        lat (float): Latitude of the point.\n",
    "        lon (float): Longitude of the point.\n",
    "        axis_direction (tuple): Direction vector of the axis (x, y).\n",
    "        crs (str): CRS for projecting to meters (default: EPSG:3857).\n",
    "\n",
    "    Returns:\n",
    "        float: One-dimensional projection value in meters.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the transformer for projecting lat/lon to the desired CRS\n",
    "    transformer = Transformer.from_crs(\"EPSG:4326\", crs, always_xy=True)\n",
    "    \n",
    "    # Project the latitude and longitude to meters\n",
    "    x, y = transformer.transform(lon, lat)\n",
    "    \n",
    "    # Normalize the axis direction vector\n",
    "    axis_vector = np.array(axis_direction)\n",
    "    axis_unit_vector = axis_vector / np.linalg.norm(axis_vector)\n",
    "    \n",
    "    # Compute the projection of the point onto the axis\n",
    "    projection_value = np.dot([x, y], axis_unit_vector)\n",
    "    return projection_value\n",
    "\n",
    "def find_traffic_light_id(row, segments_gdf):\n",
    "    \"\"\"\n",
    "    Find the nearest segment ID to a given row in a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        row (pd.Series): Row in a DataFrame with columns 'lat' and 'lon'.\n",
    "        segments_gdf (gpd.GeoDataFrame): GeoDataFrame with segment geometries.\n",
    "\n",
    "    Returns:\n",
    "        int: ID of the nearest segment.\n",
    "    \"\"\"\n",
    "    # Create a GeoDataFrame for the point\n",
    "    point = gpd.GeoDataFrame(\n",
    "        geometry=[loads(f\"POINT ({row['lat']} {row['lon']})\")], crs=\"EPSG:4326\" # Make sure lat and lon is given completely right! Lat first then lon\n",
    "    )\n",
    "    \n",
    "    # Reproject both point and segments to a projected CRS for accurate distance calculations\n",
    "    projected_crs = \"EPSG:4326\"  # Common projected CRS for distance calculations\n",
    "    point_proj = point.to_crs(projected_crs)\n",
    "    segments_gdf_proj = segments_gdf.to_crs(projected_crs)\n",
    "    max_distance = float(\"inf\")\n",
    "    nearest_segment_id = None\n",
    "    for index, row in segments_gdf_proj.iterrows():\n",
    "        distance = row.geometry.distance(point_proj.geometry[0])\n",
    "        if distance < max_distance:\n",
    "            max_distance = distance\n",
    "            nearest_segment_id = index\n",
    "    return nearest_segment_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the main dataframe\n",
    "main_df = pd.read_csv(\"20181024_d1_0830_0900_traffic_segmented.csv\")\n",
    "# loading the traffic light states\n",
    "with open(\"20181024_d1_0830_0900_traffic_light_states.json\") as f:\n",
    "    traffic_info = json.load(f)\n",
    "# loading the segments\n",
    "segments_gdf = gpd.read_file(\"20181024_d1_0830_0900_traffic_lights_segments.csv\")\n",
    "# Convert to GeoDataFrame\n",
    "if \"geometry\" in segments_gdf.columns:\n",
    "    # Convert 'geometry' to shapely objects if needed\n",
    "    segments_gdf[\"geometry\"] = segments_gdf[\"geometry\"].apply(loads)\n",
    "    # Create GeoDataFrame and set the CRS to WGS 84 (latitude/longitude)\n",
    "    segments_gdf = gpd.GeoDataFrame(segments_gdf, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "else:\n",
    "    raise ValueError(\"The DataFrame does not have a 'geometry' column.\")\n",
    "\n",
    "# Reproject to a projected CRS (replace EPSG code with appropriate UTM zone)\n",
    "segments_gdf = segments_gdf.to_crs(\"EPSG:25832\")  # Example for UTM Zone 32N\n",
    "\n",
    "# Calculate lengths\n",
    "segments_gdf[\"length\"] = segments_gdf.geometry.length\n",
    "segments_gdf = segments_gdf.to_crs(\"EPSG:4326\")  # Example for UTM Zone 32N\n",
    "\n",
    "lon_one_axis_trajectory = []\n",
    "lat_one_axis_trajectory = []\n",
    "for i, row in segments_gdf.iterrows():\n",
    "    lat_one_axis_trajectory.append(lat_lon_to_axis(row.geometry.coords.xy[0][1], row.geometry.coords.xy[0][0], crs=\"EPSG:4326\"))\n",
    "    lon_one_axis_trajectory.append(lat_lon_to_axis(row.geometry.coords.xy[1][1], row.geometry.coords.xy[1][0], crs=\"EPSG:4326\"))\n",
    "\n",
    "segments_gdf[\"lon_one_axis_trajectory\"] = lon_one_axis_trajectory\n",
    "segments_gdf[\"lat_one_axis_trajectory\"] = lat_one_axis_trajectory\n",
    "\n",
    "# Calculate total length\n",
    "total_length = segments_gdf[\"length\"].sum()\n",
    "\n",
    "# loading the traffic lights\n",
    "traffic_lights_df = pd.read_csv(\"traffic_lights.csv\")\n",
    "# find traffic light segment id\n",
    "traffic_lights_df[\"nearest_segment_id\"] = traffic_lights_df.apply(find_traffic_light_id, axis=1, segments_gdf=segments_gdf)\n",
    "traffic_lights_df = traffic_lights_df.iloc[:5, :]\n",
    "# loading the traffic light states\n",
    "with open(\"traffic_info_dict.pkl\", \"rb\") as f:\n",
    "    traffic_lights_dict_states = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "main_df_truncated_with_cell = pd.read_csv(\"20181024_d1_0830_0900_segmented_oneaxistrajectory_cell.csv\")\n",
    "\n",
    "# Group by the desired columns and aggregate the vehicle IDs into a frozenset\n",
    "grouped_with_veh_ids = main_df_truncated_with_cell.groupby([\"link_id\", \"time\"]).agg({\n",
    "    \"veh_id\": lambda x: frozenset(x)  # Use frozenset instead of set\n",
    "}).reset_index()\n",
    "\n",
    "# Merge the new column back into the original dataframe\n",
    "main_df_truncated_with_cell = main_df_truncated_with_cell.merge(grouped_with_veh_ids, on=[\"link_id\", \"time\"], suffixes=('', '_list'))\n",
    "\n",
    "# Rename the new column for clarity\n",
    "main_df_truncated_with_cell.rename(columns={\"veh_id_list\": \"veh_id_list\"}, inplace=True)\n",
    "\n",
    "# Display the shapes\n",
    "duplicate_dropped = main_df_truncated_with_cell.drop_duplicates(subset=[\"link_id\", \"time\", \"veh_id_list\"])[[\"veh_id_list\", \"link_id\", \"time\"]]\n",
    "\n",
    "\n",
    "link_dataframes = {}\n",
    "for segment_id in duplicate_dropped[\"link_id\"].unique():\n",
    "    \n",
    "    segment_df = duplicate_dropped[duplicate_dropped[\"link_id\"] == segment_id].reset_index().drop(columns=[\"index\"])\n",
    "    segment_df = segment_df.sort_values(\"time\")\n",
    "\n",
    "    segment_df[\"N_down\"] = segment_df[\"veh_id_list\"] - segment_df[\"veh_id_list\"].shift(1)\n",
    "    segment_df[\"N_up\"] = segment_df[\"veh_id_list\"].shift(-1) - segment_df[\"veh_id_list\"] \n",
    "\n",
    "    segment_df[\"N_cumsum_down\"] = segment_df[\"N_down\"].iloc[1:].apply(len).cumsum()\n",
    "    segment_df[\"N_cumsum_up\"] = segment_df[\"N_up\"].iloc[:-1].apply(len).cumsum()\n",
    "    \n",
    "    link_dataframes[segment_id] = segment_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulativecount_up(time, segment_id):\n",
    "    segment_df = link_dataframes[segment_id]\n",
    "    closest_time = segment_df[segment_df['time'] <= time].time.max()\n",
    "    return segment_df[segment_df['time'] == closest_time][\"N_cumsum_up\"].values[0]\n",
    "\n",
    "def cumulativecount_down(time, segment_id):\n",
    "    segment_df = link_dataframes[segment_id]\n",
    "    closest_time = segment_df[segment_df['time'] <= time].time.max()\n",
    "    return segment_df[segment_df['time'] == closest_time][\"N_cumsum_up\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import CTMParameters\n",
    "from helper import *\n",
    "import math\n",
    "\n",
    "# Notes for Maziar:\n",
    "## Do not use CTMParameters().object at all! If you use it, it will create a new object every time you call it. Instead, use the instance that you make of it!\n",
    "## Try avoidng using the istance of CTMParemeters as a global object. Instead, pass it as an argument to the functions that need it.\n",
    "## The docstring could be formatted for clarity: 1- Mention all parameters and their expected types! 2- Include an explanation of the function's output!\n",
    "## Check for invalid or empty densities.\n",
    "## Use descriptive variable names for better readability.\n",
    "## Avoid magic numbers like 1 for the green light status; use constants instead.\n",
    "\n",
    "\n",
    "# load params\n",
    "ctm_params = CTMParameters() # for now, we use same parameters we had in CTM model\n",
    "\n",
    "# define the function for finding cumulative counts\n",
    "N_upstr = cumulativecount_up\n",
    "N_downstr = cumulativecount_down\n",
    "\n",
    "## Cell transmission model: update cell density\n",
    "# time: current simulation time\n",
    "# arguments: N_upstrs: cumulative count of vehicles in upstream at a given time. I'll pass N_downstr(t) and it should tell me the cumulative count\n",
    "# N_downstr: cumulative count at link downstream at time t (current time)\n",
    "# entry_flow: for now constant, entering to the link in vehicles per second\n",
    "# assumptions: jam density and max flow are constant for all cells\n",
    "def update_point_queue(time, segment_id, entry_flow, traffic_lights_df, traffic_lights_dict_states):\n",
    "\n",
    "    # check if there is a traffic light at the end of the segment\n",
    "    if is_tl(segment_id, traffic_lights_df):\n",
    "        # check the status of the traffic light\n",
    "        if tl_status(time, segment_id, traffic_lights_df, traffic_lights_dict_states) == 1: # green light\n",
    "            # find the link sending flow using point queue model \n",
    "            sending_flow = math.min( N_upstr(time + ctm_params.time_step - (ctm_params.segment_length/ctm_params.free_flow_speed), segment_id) - N_downstr, ctm_params.max_flow*ctm_params.time_step)\n",
    "        else:\n",
    "            sending_flow = 0\n",
    "    else: # no traffic light at the end of the link\n",
    "        sending_flow = math.min( N_upstr(time + ctm_params.time_step - (ctm_params.segment_length/ctm_params.free_flow_speed), segment_id) - N_downstr, ctm_params.max_flow*ctm_params.time_step)\n",
    "\n",
    "    # find the number of vehicles in the link at the next time step\n",
    "    n_current = N_downstr(time) - N_upstr   # current number of vehicles\n",
    "    n_updated = n_current + entry_flow * ctm_params.time_step -  sending_flow \n",
    "\n",
    "    link_outflow = sending_flow\n",
    "    link_density = n_updated / ctm_params.segment_length\n",
    "    return link_density, link_outflow    # please note the   order \n",
    "\n",
    "# test the function\n",
    "# Density = [0.1, 0.15, 0, 0.2, 0.1, 0.1]\n",
    "# entry_flow = 0\n",
    "# time = 5\n",
    "# updated_density = update_cell_status(time, 1, Density, ctm_params, entry_flow)\n",
    "# print(updated_density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(8.0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
